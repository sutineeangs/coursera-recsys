{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "quick-double",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies Imported\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk #for stemming process\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import json\n",
    "print('Dependencies Imported')\n",
    "# import test\n",
    "# print(test.test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "chief-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coursera Course Recommendation System+WebApp\n",
    "# https://www.kaggle.com/code/sagarbapodara/coursera-course-recommendation-system-webapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "capable-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCourses():\n",
    "    # Read file\n",
    "    data = pd.read_csv(\"../data/Coursera.csv\")\n",
    "#     data = data[['Course Name','Difficulty Level','Course Description','Skills']]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "synthetic-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJsonData(df):\n",
    "    result = df.to_json(orient=\"records\")\n",
    "    parsed = json.loads(result)\n",
    "    return parsed\n",
    "#     return json.dumps(parsed, indent=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "central-exception",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the stemming function\n",
    "# def stem(text, ps):\n",
    "#     y=[]\n",
    "    \n",
    "#     # Stemming Process\n",
    "# #     ps = PorterStemmer()\n",
    "    \n",
    "#     for i in text.split():\n",
    "#         y.append(ps.stem(i))\n",
    "    \n",
    "#     return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "theoretical-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendation Function\n",
    "def recommend1(course):\n",
    "    \n",
    "    # Get data\n",
    "    courses = getCourses()\n",
    "    data = courses.copy()\n",
    "    \n",
    "    # Removing spaces between the words (Lambda funtions can be used as well)\n",
    "    data['course_name'] = data['Course Name'].copy()\n",
    "    data['Course Name'] = data['Course Name'].str.replace(' ',',')\n",
    "    data['Course Name'] = data['Course Name'].str.replace(',,',',')\n",
    "    data['Course Name'] = data['Course Name'].str.replace(':','')\n",
    "    \n",
    "    courses['course_name_index'] = data['Course Name'].str.replace(',',' ')\n",
    "    \n",
    "    data['Course Description'] = data['Course Description'].str.replace(' ',',')\n",
    "    data['Course Description'] = data['Course Description'].str.replace(',,',',')\n",
    "    data['Course Description'] = data['Course Description'].str.replace('_','')\n",
    "    data['Course Description'] = data['Course Description'].str.replace(':','')\n",
    "    data['Course Description'] = data['Course Description'].str.replace('(','')\n",
    "    data['Course Description'] = data['Course Description'].str.replace(')','')\n",
    "\n",
    "    #removing paranthesis from skills columns \n",
    "    data['Skills'] = data['Skills'].str.replace('(','')\n",
    "    data['Skills'] = data['Skills'].str.replace(')','')\n",
    "    \n",
    "    data['tags'] = data['Course Name'] + data['Difficulty Level'] + data['Course Description'] + data['Skills']\n",
    "    \n",
    "    new_df = data[['Course Name','tags']]\n",
    "    new_df['tags'] = data['tags'].str.replace(',',' ')\n",
    "    new_df['Course Name'] = data['Course Name'].str.replace(',',' ')\n",
    "    new_df.rename(columns = {'Course Name':'course_name'}, inplace = True)\n",
    "    new_df['tags'] = new_df['tags'].apply(lambda x:x.lower()) #lower casing the tags column\n",
    "    \n",
    "    # Text Vectorization\n",
    "    cv = CountVectorizer(max_features=5000,stop_words='english')\n",
    "    vectors = cv.fit_transform(new_df['tags']).toarray()\n",
    "    \n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    #defining the stemming function\n",
    "    def stem(text):\n",
    "        y=[]\n",
    "    \n",
    "        for i in text.split():\n",
    "            y.append(ps.stem(i))\n",
    "    \n",
    "        return \" \".join(y)\n",
    "    \n",
    "    new_df['tags'] = new_df['tags'].apply(stem) #applying stemming on the tags column\n",
    "    \n",
    "    similarity = cosine_similarity(vectors)\n",
    "    \n",
    "    course_index = new_df[new_df['course_name'] == course].index[0]\n",
    "    distances = similarity[course_index]\n",
    "    course_list = sorted(list(enumerate(distances)),reverse=True, key=lambda x:x[1])[1:7]\n",
    "    \n",
    "    course_names = []\n",
    "    for i in course_list:\n",
    "        course_names.append(new_df.iloc[i[0]].course_name)\n",
    "    #print(course_names)\n",
    "    return courses.set_index('course_name_index').loc[course_names].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "saving-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coursera Course Recommendation Engine \n",
    "# https://www.kaggle.com/code/brijlaldhankour/coursera-course-recommendation-engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "thirty-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating autocpt arguments \n",
    "def func(pct, allvalues): \n",
    "    absolute = int(pct / 100.*np.sum(allvalues)) \n",
    "    return \"{:.1f}%\\n({:d} g)\".format(pct, absolute) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "noted-charles",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotGraph1():\n",
    "    # Get data\n",
    "    courses = getCourses()\n",
    "    df = courses.copy()\n",
    "    \n",
    "    # This dataframe contains some useless columns which must be dropped for a better analytics result\n",
    "    uc = ['Course URL']  # uc means useless columns\n",
    "    df = df.drop(columns=uc)\n",
    "    \n",
    "    # Data Inferencing\n",
    "    r,c = df.shape\n",
    "    #======================== Plot Graph =====================================#\n",
    "    # Data Visualization\n",
    "    datavis = df['Difficulty Level'].value_counts()\n",
    "    datavis\n",
    "    mag = datavis.index\n",
    "    data = datavis.values\n",
    "    explode = (0.1,0.0,0.0,0.0,0.0) \n",
    "\n",
    "    # Creating color parameters \n",
    "    colors = (\"lightblue\",\"crimson\",\"yellow\",\"green\",\"violet\") \n",
    "\n",
    "    # Wedge properties \n",
    "    wp = { 'linewidth' : 1, 'edgecolor' : \"white\" } \n",
    "\n",
    "    # Creating plot \n",
    "    fig, ax = plt.subplots(figsize =(15, 10)) \n",
    "    wedges, texts, autotexts = ax.pie(data,  \n",
    "                                      autopct = lambda pct: func(pct, data), \n",
    "                                      explode = explode,  \n",
    "                                      labels = mag, \n",
    "                                      shadow = True, \n",
    "                                      colors = colors, \n",
    "                                      startangle = 90, \n",
    "                                      wedgeprops = wp, \n",
    "                                      textprops = dict(color =\"black\")) \n",
    "\n",
    "    # Adding legend \n",
    "    ax.legend(wedges, mag, \n",
    "              title =\"Values\", \n",
    "              loc =\"center left\", \n",
    "              bbox_to_anchor =(1, 0, 0.5, 1)) \n",
    "\n",
    "    plt.setp(autotexts, size = 10, weight =\"bold\") \n",
    "    ax.set_title(\"Payment type of course\\n\",size=19) \n",
    "\n",
    "    # show plot \n",
    "    plt.show()\n",
    "    #=========================================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "toxic-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotGraph2():\n",
    "    # Get data\n",
    "    courses = getCourses()\n",
    "    df = courses.copy()\n",
    "    \n",
    "    # This dataframe contains some useless columns which must be dropped for a better analytics result\n",
    "    uc = ['Course URL']  # uc means useless columns\n",
    "    df = df.drop(columns=uc)\n",
    "    \n",
    "    # Data Inferencing\n",
    "    r,c = df.shape\n",
    "    #======================== Plot Graph =====================================#\n",
    "    df['Course Rating'].value_counts()\n",
    "    df = df[df['Course Rating'] != 'Not Calibrated']\n",
    "    df['Course Rating'] = df['Course Rating'].astype(float)\n",
    "    plt.figure(figsize=(18,7))\n",
    "    sns.countplot(data=df,x='Course Rating',palette='plasma')\n",
    "    plt.xlabel('Course Ratings',fontsize='16',color='blue')\n",
    "    plt.ylabel('Number of courses',fontsize='16',color='blue')\n",
    "    plt.xticks(fontsize='14',color='green')\n",
    "    plt.yticks(fontsize='14',color='red')\n",
    "    plt.title(\"Count of course types\\n\",fontsize=24,fontweight='bold',color='indigo')\n",
    "    #=========================================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "comprehensive-astronomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendation Function\n",
    "def recommend2(course_title):\n",
    "    \n",
    "    # Get data\n",
    "    courses = getCourses()\n",
    "    df = courses.copy()\n",
    "    \n",
    "    # This dataframe contains some useless columns which must be dropped for a better analytics result\n",
    "    uc = ['Course URL']  # uc means useless columns\n",
    "    df = df.drop(columns=uc)\n",
    "    \n",
    "    # Data Inferencing\n",
    "    r,c = df.shape\n",
    "    #print(\"Number of customers  = \",r)\n",
    "    #print(\"Number of parameters = \",c)\n",
    "    #print(df.info())\n",
    "    #print(\"Are there any missing values in the dataset ?\",df.isna().values.any())\n",
    "\n",
    "    # complete summary of dataset\n",
    "    #df.describe().T\n",
    "    \n",
    "    df = df[df['Course Rating'] != 'Not Calibrated']\n",
    "    df['Course Rating'] = df['Course Rating'].astype(float)\n",
    "    #=========================================================================#\n",
    "    # Filtering required data\n",
    "    df2 = df[df['Course Rating'] > 4.0]\n",
    "    #=========================================================================#\n",
    "    # Making NLP Model for Recommendation Engine\n",
    "    cv=TfidfVectorizer()\n",
    "    tfidf_matrix=cv.fit_transform(df['Course Name'])\n",
    "    course_user = df.pivot_table(columns='Course Name',values='Course Rating')\n",
    "    course_user.head()\n",
    "    df = df.rename(columns={'Course Name':'course_title'})\n",
    "    \n",
    "    cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "    indices=pd.Series(df.index,index=df['course_title'])\n",
    "    titles=df['course_title']\n",
    "\n",
    "    # Running Recommendation Engine on variety of course genres\n",
    "    idx = indices[course_title]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    course_indices = [i[0] for i in sim_scores]\n",
    "    return courses.loc[titles.iloc[course_indices].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fleet-island",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test functions\n",
    "# recommend1('Business Strategy Business Model Canvas Analysis with Miro') \n",
    "\n",
    "# plotGraph1()\n",
    "# plotGraph2()\n",
    "\n",
    "# TOPIC : 1 TV shows and telecast\n",
    "# print(\"--------------- Similar courses to your search --------------:\\n\")\n",
    "# recommend2('Write A Feature Length Screenplay For Film Or Television')\n",
    "\n",
    "# TOPIC : 2 Database and related courses\n",
    "# print(\"--------------- Similar courses to your search --------------:\\n\")\n",
    "# recommend2('Retrieve Data using Single-Table SQL Queries')\n",
    "\n",
    "# TOPIC : 3 Finance related\n",
    "# print(\"--------------- Similar courses to your search --------------:\\n\")\n",
    "# recommend2('Finance for Managers')\n",
    "# getJsonData(recommend2('Finance for Managers'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-strengthening",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
